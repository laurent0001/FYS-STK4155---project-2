# -*- coding: utf-8 -*-
"""Project_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14iwIDMbXYxTPkvfnAMmGFHXtXD4BIlpL
"""

import sklearn
print('The scikit-learn version is {}.'.format(sklearn.__version__))

!pip install scikit-plot

import os
print(os.getcwd())

from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
from matplotlib import scale
from matplotlib.ticker import LinearLocator, FormatStrFormatter
from random import random, seed
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, confusion_matrix, accuracy_score, roc_auc_score
from sklearn.model_selection import KFold
from sklearn.linear_model import Ridge
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.utils import resample
from sklearn.compose import ColumnTransformer
import os
import time
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy as scp
import seaborn
import scikitplot as skplt



"""Make data"""
np.random.seed(1)

def FrankeFunction(x,y):
  term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))
  term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))
  term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))
  term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)
  return term1 + term2 + term3 + term4

def f_noise_franke(x, y):
  shape_z = np.shape(FrankeFunction(x,y))
  noise_z = 0.1*np.random.randn(shape_z[0], shape_z[1])
  return noise_z

x = np.arange(0, 1, 0.025)
y = np.arange(0, 1, 0.025)
x, y = np.meshgrid(x,y)
z = FrankeFunction(x, y) + f_noise_franke(x, y)

# Plot the surface.
fig = plt.figure()
ax = fig.gca(projection="3d")
surf = ax.plot_surface(x, y, z, cmap=cm.coolwarm,linewidth=0, 
                       antialiased=False)
# Customize the z axis.
ax.set_zlim(-0.10, 1.40)
ax.zaxis.set_major_locator(LinearLocator(10))
ax.zaxis.set_major_formatter(FormatStrFormatter("%.02f"))
# Add a color bar which maps values to colors.
fig.colorbar(surf, shrink=0.5, aspect=5)
plt.show()

# Unravel xy meshgrid and z matrix into vectors
x = np.ravel(x)
y = np.ravel(y)
z = np.ravel(z)

# Create design matrix of polynomial degree 5
X = np.c_[np.ones(len(x)), # We have to try different polynomial degrees for the report and discuss which ones are best
          x, y, 
          x*x, y*y, x*y,
          x*x*x, x*x*y, x*y*y, y*y*y,
          x*x*x*x, x*x*x*y, x*x*y*y, x*y*y*y, y*y*y*y,
          x*x*x*x*x, x*x*x*x*y, x*x*x*y*y, x*x*y*y*y, x*y*y*y*y, y*y*y*y*y]
DesignMatrix = pd.DataFrame(X)
DesignMatrix.columns = [
          '1',
          "x", "y", 
          "x^2", "xy", "y^2",
          "x^3", "x^2y", "xy^2", "y^3",
          "x^4", "x^3y", "x^2y^2", "xy^3", "y^4",
          "x^5", "x^4y", "x^3y^2", "x^2y^3", "xy^4", "y^5"]

"""Regression functions"""
def BetaRidge (X, y, lambda_value):
  beta_ridge = np.linalg.pinv(X.T.dot(X) + lambda_value*np.identity(np.shape(X.T.dot(X))[1])).dot(X.T).dot(y)
  #ytilde_ridge = X @ beta_ridge
  return beta_ridge

def optimal_lambda_ridge(MSE_list, lambdas):
    mse = np.amin(MSE_list)
    highest_lambda_at_lowest_MSE = lambdas[np.where(MSE_list == np.amin(MSE_list))[0][-1]]
    return mse, highest_lambda_at_lowest_MSE

def find_optimal_lambda_ridge(design_mat, k=5, shuffle=True):
    lambdas = np.logspace(-12, 5, 1000)
    estimated_mse_KFold_own = ridge_regression_own(X, lambdas, k, shuffle)[0]
    optimal_lambda = optimal_lambda_ridge(estimated_mse_KFold_own, lambdas)[1]
    return optimal_lambda

def ridge_regression_own(design_mat, lambdas, k, shuffle=True):
  kfold = KFold(n_splits = k, shuffle=shuffle, random_state=5)
  scores_KFold = np.zeros((len(lambdas), k))
  bias_Kfold = np.zeros((len(lambdas), k))
  variance_Kfold = np.zeros((len(lambdas), k))
  mse_train_Kfold = np.zeros((len(lambdas), k))
  i = 0
  for lmb in lambdas:
      j = 0
      for train_inds, test_inds in kfold.split(design_mat):
          Xtrain = design_mat[train_inds]
          ztrain = z[train_inds]
          Xtest = design_mat[test_inds]
          ztest = z[test_inds]
          #print("ztest", ztest.shape)
          z_pred = Xtest @ BetaRidge(Xtrain, ztrain, lmb)
          #print("z_pred", z_pred.shape)
          z_pred_train = Xtrain @ BetaRidge(Xtrain, ztrain, lmb)
          scores_KFold[i,j] = np.sum( (z_pred - ztest)**2 )/np.size(z_pred)
          bias_Kfold[i,j] = np.sum( (ztest - np.mean(z_pred))**2 )/np.size(z_pred)
          variance_Kfold[i,j] = np.sum( np.var(z_pred) )/np.size(z_pred)
          mse_train_Kfold[i,j] = np.sum( (z_pred_train - ztrain)**2 )/np.size(z_pred_train)
          j += 1
      i += 1
  estimated_mse_KFold_own = np.mean(scores_KFold, axis = 1)
  estimated_bias_Kfold_own = np.mean(bias_Kfold, axis = 1)
  estimated_variance_Kfold_own = np.mean(variance_Kfold, axis = 1)
  estimated_mse_train_Kfold_own = np.mean(mse_train_Kfold, axis = 1)
  return estimated_mse_KFold_own, estimated_bias_Kfold_own, estimated_variance_Kfold_own, estimated_mse_train_Kfold_own

"""Test ridge regression functions"""

#print("optimal_lambda_ridge", find_optimal_lambda_ridge(X))

"""Load credit card data"""
# https://compphysics.github.io/MachineLearning/doc/pub/LogReg/html/LogReg.html
# https://bradzzz.gitbooks.io/ga-seattle-dsi/content/dsi/dsi_05_classification_databases/2.1-lesson/assets/datasets/DefaultCreditCardClients_yeh_2009.pdf
# https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients
# https://compphysics.github.io/MachineLearning/doc/pub/Splines/html/Splines-bs.html
# https://compphysics.github.io/MachineLearning/doc/pub/NeuralNet/html/NeuralNet-bs.html
# http://neuralnetworksanddeeplearning.com/

# Reading file into data frame

#cwd = os.getcwd() # For getting data from local machine
#filename = cwd + '/default of credit card clients.xls' # For getting data from local machine
#df = pd.read_excel(filename, header=1, skiprows=0, index_col=0, na_values=nanDict) # For getting data from local machine

url = "https://github.com/laurent0001/FYS-STK4155---project-2/blob/master/default%20of%20credit%20card%20clients.xls?raw=true"
nanDict = {}
df = pd.read_excel(url, header=1, skiprows=0, index_col=0, na_values=nanDict)


df.rename(index=str, columns={"default payment next month": "defaultPaymentNextMonth"}, inplace=True)

# Features and targets 
X = df.loc[:, df.columns != 'defaultPaymentNextMonth'].values
y = df.loc[:, df.columns == 'defaultPaymentNextMonth'].values
print("y.shape", y.shape)

# Categorical variables to one-hot's
onehotencoder = OneHotEncoder(categories='auto')

# Train-test split
trainingShare = 0.5 
seed  = 1
XTrain, XTest, yTrain, yTest=train_test_split(X, y, train_size=trainingShare, \
                                              test_size = 1-trainingShare,
                                             random_state=seed)

# Input Scaling
sc = StandardScaler()
XTrain = sc.fit_transform(XTrain)
XTest = sc.transform(XTest)

# One-hot's of the target vector
Y_train_onehot, Y_test_onehot = onehotencoder.fit_transform(yTrain), onehotencoder.fit_transform(yTest)

# Remove instances with zeros only for past bill statements or paid amounts
'''
df = df.drop(df[(df.BILL_AMT1 == 0) &
                (df.BILL_AMT2 == 0) &
                (df.BILL_AMT3 == 0) &
                (df.BILL_AMT4 == 0) &
                (df.BILL_AMT5 == 0) &
                (df.BILL_AMT6 == 0) &
                (df.PAY_AMT1 == 0) &
                (df.PAY_AMT2 == 0) &
                (df.PAY_AMT3 == 0) &
                (df.PAY_AMT4 == 0) &
                (df.PAY_AMT5 == 0) &
                (df.PAY_AMT6 == 0)].index)
'''
df = df.drop(df[(df.BILL_AMT1 == 0) &
                (df.BILL_AMT2 == 0) &
                (df.BILL_AMT3 == 0) &
                (df.BILL_AMT4 == 0) &
                (df.BILL_AMT5 == 0) &
                (df.BILL_AMT6 == 0)].index)

df = df.drop(df[(df.PAY_AMT1 == 0) &
                (df.PAY_AMT2 == 0) &
                (df.PAY_AMT3 == 0) &
                (df.PAY_AMT4 == 0) &
                (df.PAY_AMT5 == 0) &
                (df.PAY_AMT6 == 0)].index)

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

lambdas=np.logspace(-5,7,13)
parameters = [{'C': 1./lambdas, "solver":["lbfgs"]}]#*len(parameters)}]
scoring = ['accuracy', 'roc_auc']
logReg = LogisticRegression()
gridSearch = GridSearchCV(logReg, parameters, cv=5, scoring=scoring, refit='roc_auc') 

# "refit" gives the metric used deciding best model. 
# See more http://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html
gridSearch.fit(XTrain, yTrain.ravel())

def gridSearchSummary(method, scoring):
    """Prints best parameters from Grid search
    and AUC with standard deviation for all 
    parameter combos """
    
    method = eval(method)
    if scoring == 'accuracy':
        mean = 'mean_test_score'
        sd = 'std_test_score'
    elif scoring == 'auc':
        mean = 'mean_test_roc_auc'
        sd = 'std_test_roc_auc'
    print("Best: %f using %s" % (method.best_score_, method.best_params_))
    means = method.cv_results_[mean]
    stds = method.cv_results_[sd]
    params = method.cv_results_['params']
    for mean, stdev, param in zip(means, stds, params):
        print("%f (%f) with: %r" % (mean, stdev, param))

def createConfusionMatrix(method, printOut=True):
    """
    Computes and prints confusion matrices, accuracy scores,
    and AUC for test and training sets 
    """
    confusionArray = np.zeros(6, dtype=object)
    method = eval(method)
    
    # Train
    yPredTrain = method.predict(XTrain)
    yPredTrain = (yPredTrain > 0.5)
    cm = confusion_matrix(
        yTrain, yPredTrain) 
    cm = np.around(cm/cm.sum(axis=1)[:,None], 2)
    confusionArray[0] = cm
    
    accScore = accuracy_score(yTrain, yPredTrain)
    confusionArray[1] = accScore
    
    AUC = roc_auc_score(yTrain, yPredTrain)
    confusionArray[2] = AUC
    
    if printOut:
        print('\n###################  Training  ###############')
        print('\nTraining Confusion matrix: \n', cm)
        print('\nTraining Accuracy score: \n', accScore)
        print('\nTrain AUC: \n', AUC)
    
    # Test
    yPred = method.predict(XTest)
    yPred = (yPred > 0.5)
    cm = confusion_matrix(
        yTest, yPred) 
    cm = np.around(cm/cm.sum(axis=1)[:,None], 2)
    confusionArray[3] = cm
    
    accScore = accuracy_score(yTest, yPred)
    confusionArray[4] = accScore
    
    AUC = roc_auc_score(yTest, yPred)
    confusionArray[5] = AUC
    
    if printOut:
        print('\n###################  Testing  ###############')
        print('\nTest Confusion matrix: \n', cm)
        print('\nTest Accuracy score: \n', accScore)
        print('\nTestAUC: \n', AUC)    
    
    return confusionArray

seaborn.set(style="white", context="notebook", font_scale=1.5, 
            rc={"axes.grid": True, "legend.frameon": False,
"lines.markeredgewidth": 1.4, "lines.markersize": 10})
seaborn.set_context("notebook", font_scale=1.5, rc={"lines.linewidth": 4.5})

yPred = gridSearch.predict_proba(XTest) 
print(yTest.ravel().shape, yPred.shape)

#skplt.metrics.plot_cumulative_gain(yTest.ravel(), yPred_onehot)
skplt.metrics.plot_cumulative_gain(yTest.ravel(), yPred)

defaults = sum(yTest == 1)
total = len(yTest)
defaultRate = defaults/total
def bestCurve(defaults, total, defaultRate):
    x = np.linspace(0, 1, total)
    
    y1 = np.linspace(0, 1, defaults)
    y2 = np.ones(total-defaults)
    y3 = np.concatenate([y1,y2])
    return x, y3

x, best = bestCurve(defaults=defaults, total=total, defaultRate=defaultRate)    
plt.plot(x, best)    


plt.show()